# Define the data path
data_path="hypo_dataset/contextvqa_full.json"

val_data_path="hypo_dataset/cot_contextvqa_split/val_contextvqa.json"
train_data_path="hypo_dataset/cot_contextvqa_split/train_contextvqa.json"
test_data_path="hypo_dataset/cot_contextvqa_split/test_contextvqa.json"

cot_contextvqa_data_path="contextvqa_llava-onevision-qwen2-7b-ov-hf_with_label_align_and_cot_gen.json"
teacher_cache_dir="teacher_cache/"

images_dir="/gpfs/home/ym621/gavin/Hypo3D/hypo_dataset/dataset/top_view_with_label_rotated"

lora_adapter_normal="lora_finetuned_llava_llava-hf_llava-onevision-qwen2-7b-ov-hf"
lora_adapter_cot_7b="lora_distilled_llava_llava-hf_llava-onevision-qwen2-7b-ov-hf"
lora_adapter_cot_0_5b="lora_distilled_llava_llava-hf_llava-onevision-qwen2-0.5b-ov-hf"
lora_adapter_path_0_5b="lora_finetuned_llava_llava-hf_llava-onevision-qwen2-0.5b-ov-hf"

# Check if the file exists before running the script
if [[ -f "$data_path" ]]; then
    echo "Processing file: $data_path"

    echo "LLava-OV 7B: Base/Zero-shot model"
    python 2D-VLM/llava-ov/bertscore_evaluate.py -f "$train_data_path" -m "llava-hf/llava-onevision-qwen2-7b-ov-hf"

    echo "LLava-OV 7B: Adapter tuning (generate LoRA adapter) with cross entropy loss function"
    python 2D-VLM/llava-ov/normal_lora_finetuning.py -f "$train_data_path" -m "llava-hf/llava-onevision-qwen2-7b-ov-hf" -i "$images_dir" -e "$val_data_path" 

    # Using student model's tokenizer to get vocab_size to match for the raw_logits generated.
   echo "LLaVA-OV 7B (teacher) with normal LoRA adapter: Running inference on train dataset to generate CoT + raw logits"
   python 2D-VLM/llava-ov/cot_gen.py \
       -f "$train_data_path" \
       -m "llava-hf/llava-onevision-qwen2-7b-ov-hf" \
       -a "$lora_adapter_normal" \
       -s "llava-hf/llava-onevision-qwen2-0.5b-ov-hf" \
	
   echo "LLaVA-OV 0.5B (student) Finetuning on CoT generated by LLaVA-OV 7B (KL Div Loss)"
   python 2D-VLM/llava-ov/cot_lora_finetuning.py \
       -f "$cot_contextvqa_data_path" \
       -m "llava-hf/llava-onevision-qwen2-0.5b-ov-hf" \
       -i "$images_dir" \
       -e "$val_data_path" \
       -c "$teacher_cache_dir"

   echo "RUNNING BLIND AND NORMAL TEST"

   echo "[BLIND TEST] Running baseline student model (llava-ov-0.5b) to see baseline model performance"
   python 2D-VLM/llava-ov/blind_evaluate.py \
	    -f "$val_data_path" \
	    -m "llava-hf/llava-onevision-qwen2-0.5b-ov-hf" \
        --blind_test

   echo "[NORMAL TEST] Running baseline student model (llava-ov-0.5b) to see baseline model performance"
   python 2D-VLM/llava-ov/evaluate.py \
	    -f "$val_data_path" \
	    -m "llava-hf/llava-onevision-qwen2-0.5b-ov-hf"

    echo "[BLIND TEST] LLava-OV 0.5B: Base/Zero-shot model with finetuned LoRA Adapter"
    python 2D-VLM/llava-ov/blind_model_with_lora_evaluate.py \
        -f "$val_data_path" \
        -m "llava-hf/llava-onevision-qwen2-0.5b-ov-hf" \
        -a "$lora_adapter_path_0_5b" \
        --blind_test

    echo "[NORMAL TEST] LLava-OV 0.5B: Base/Zero-shot model with finetuned LoRA Adapter"
    python 2D-VLM/llava-ov/model_with_lora_evaluate.py \
        -f "$val_data_path" \
        -m "llava-hf/llava-onevision-qwen2-0.5b-ov-hf" \
        -a "$lora_adapter_path_0_5b" 

    echo "[BLIND TEST] Running Student Model (llava-ov-0.5b) with LoRA adapter (finetuned on CoT + raw_logits from teacher model)"
    python 2D-VLM/llava-ov/blind_model_with_lora_evaluate.py \
	    -f "$val_data_path" \
	    -m "llava-hf/llava-onevision-qwen2-0.5b-ov-hf" \
	    -a "$lora_adapter_cot_0_5b" \
        --blind_test

    echo "[NORMAL TEST] Running Student Model (llava-ov-0.5b) with LoRA adapter (finetuned on CoT + raw_logits from teacher model)"
    python 2D-VLM/llava-ov/model_with_lora_evaluate.py \
	    -f "$val_data_path" \
	    -m "llava-hf/llava-onevision-qwen2-0.5b-ov-hf" \
	    -a "$lora_adapter_cot_0_5b" 

else
    echo "Error: File not found: $data_path"
fi
